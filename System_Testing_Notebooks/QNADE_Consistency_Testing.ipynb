{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QNADE_Consistency_Testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r7Jtz-ux_Zg"
      },
      "source": [
        "\"\"\"\n",
        "Code to test the convergence consistency of QNADE system. \n",
        "\"\"\"\n",
        "\n",
        "\"\"\"IMPORTS\"\"\"\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "import autograd_hacks\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irqHvdLuyGiQ"
      },
      "source": [
        "def calculate_epsilons(model, s, psi_omega, B, J):\n",
        "        \"\"\"\n",
        "        Calculates the E_loc(s) for all sampled states.\n",
        "        epsilon(s) = sum(s_i * s_i+1) + B/psi_s * sum(psi_s_prime)\n",
        "\n",
        "        Args: \n",
        "            model: QNADE model \n",
        "            s: sampled states matrix\n",
        "            psi_omega: np list of wavefunction coefficients    \n",
        "            B: int, sigma_x activation\n",
        "            J: int, sigma_z activation \n",
        "\n",
        "        Returns: \n",
        "            epsilon: double, epsilon contribution for the given state \n",
        "        \"\"\"\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        N = len(s[0])\n",
        "        \n",
        "        z_term = torch.zeros([len(s)]).to(device)\n",
        "\n",
        "        # sum of the wavefunction coefficients resulting from sigma_x acting on each qubit (per sample)\n",
        "        psi_s_prime_sum = torch.zeros([len(s)]).to(device)\n",
        "\n",
        "        for i in range(N):\n",
        "            \n",
        "            if i == N-1:\n",
        "                z_term += s[:,0]*s[:,i]\n",
        "            else:\n",
        "                z_term += s[:,i]*s[:,i+1]\n",
        "\n",
        "            # calculate the sum of psi_s_prime for the sigma_x term\n",
        "            s_prime = s.clone()\n",
        "            s_prime[:,i] = -1*s_prime[:,i]\n",
        "            psi_s_prime,_,_ = model(x=s_prime, requires_grad=False) \n",
        "            psi_s_prime_sum += psi_s_prime\n",
        "        \n",
        "        x_term = psi_s_prime_sum/psi_omega\n",
        "\n",
        "        epsilons = -(J*z_term + B*x_term)\n",
        "        \n",
        "        return epsilons\n",
        "\n",
        "def calculate_expected_e(n, g):\n",
        "\n",
        "  J = 1\n",
        "  B = g\n",
        "\n",
        "  #Initialize operators and Identity matrix\n",
        "  s_z = np.array([[1,0],[0,-1]])\n",
        "  s_x = np.array([[0,1],[1,0]])\n",
        "  I = np.array([[1,0],[0,1]])\n",
        "\n",
        "  #Calculate and print energies for n qubits\n",
        "  #print(\"\\nQubits:\", n)\n",
        "  H = np.zeros((2**n,2**n))\n",
        "  H_ising = np.zeros((2**n,2**n))\n",
        "  H_tf = np.zeros((2**n,2**n))\n",
        "\n",
        "  #Generate and add Ising components to Hamiltonian\n",
        "  for i in range(0,n):\n",
        "      if i == 0 or i == n-1:\n",
        "          ising_comp = s_z\n",
        "      else:\n",
        "          ising_comp = I\n",
        "      for j in range(0,n-1):\n",
        "          if j == i or j == i-1:\n",
        "              ising_comp = np.kron(ising_comp, s_z)\n",
        "          else:\n",
        "              ising_comp = np.kron(ising_comp, I)\n",
        "      H_ising += ising_comp\n",
        "\n",
        "  #Generate and add transverse components to Hamiltonian\n",
        "  for i in range(0,n):\n",
        "      if i == 0:\n",
        "          trans_comp = s_x\n",
        "      else:\n",
        "          trans_comp = I\n",
        "      for j in range(0,n-1):\n",
        "          if j == i-1:\n",
        "              trans_comp = np.kron(trans_comp, s_x)\n",
        "          else:\n",
        "              trans_comp = np.kron(trans_comp, I)\n",
        "      H_tf += trans_comp\n",
        "      \n",
        "  H = -(J*H_ising + B*H_tf)\n",
        "\n",
        "  return min(np.linalg.eigvals(H))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6Q6iWlxyNMo"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created Jan 28 2021\n",
        "\n",
        "@authors: Alex Lidiak, Caleb Sanders\n",
        "This model takes as input a FFNN (N inputs, 2 outputs) and converts it into a \n",
        "QNADE model. \n",
        "\n",
        "The QNADE class performs the autoregressive sample generation, conditional \n",
        "wavefunction calculation, and gradient accumulation needed to optimize a \n",
        "FFNN to produce the ground state energy of an arbitrary many-body system.  \n",
        "\"\"\"\n",
        "\n",
        "class QNADE(nn.Module): # takes a FFNN model as input\n",
        "            \n",
        "    def __init__(self, model): \n",
        "        super(QNADE, self).__init__()\n",
        "        \n",
        "        self.model = model\n",
        "        self.D = self.model[0].in_features # input layer size\n",
        "        self.M = self.model[-2].out_features # output layer size\n",
        "        self.evals = [0,1]\n",
        "            \n",
        "    def forward(self, N_samples=None, x=None, requires_grad=True):\n",
        "\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        if N_samples is None and x is None: \n",
        "            raise ValueError('Must enter samples or the number of samples to' \\\n",
        "                             ' be generated')\n",
        "            \n",
        "        # if not sampling, just calculating wavefunction\n",
        "        if N_samples is None and x is not None: \n",
        "            N_samples, need_samples = x.shape[0], False\n",
        "\n",
        "        # if sampling and calculating wavefunction\n",
        "        if N_samples is not None and x is None: \n",
        "            need_samples = True\n",
        "            x = torch.zeros([N_samples,self.D],dtype=torch.float).to(device)\n",
        "            \n",
        "        # the full wavefunction is a product of the conditionals\n",
        "        WAV = torch.ones([N_samples]).to(device) \n",
        "        order = np.arange(0,self.D) # sequential autoregressive ordering \n",
        "        \n",
        "        # for gradient tracking \n",
        "        params = list(self.parameters()) \n",
        "        grads_per_param = [] \n",
        "        \n",
        "        for d in range(self.D):\n",
        "                \n",
        "            # mask enforces the autoregressive property\n",
        "            mask=torch.zeros_like(x)\n",
        "            mask[:,order[0:(d)]] = 1 \n",
        "\n",
        "            # add autograd hooks for per-sample gradient calculation \n",
        "            if not hasattr(self.model,'autograd_hacks_hooks'):             \n",
        "              autograd_hacks.add_hooks(self.model)\n",
        "            \n",
        "            # L2 normalization of masked output\n",
        "            out = F.normalize(self.model(mask*x), 2)\n",
        "            \n",
        "            # 'psi_pos' is positive bits, 'psi_neg' is negative bits \n",
        "            psi_pos = out[:,0].squeeze()\n",
        "            psi_neg = out[:,1].squeeze()\n",
        "\n",
        "            if need_samples == True:\n",
        "                \n",
        "              # sampling routine according to psi**2:\n",
        "              # convert bit values from 0 to -1\n",
        "              m = torch.distributions.Bernoulli(psi_pos**2).sample()\n",
        "              m = torch.where(m == 0, \n",
        "                              torch.tensor(-1).to(device), \n",
        "                              torch.tensor(1).to(device)) \n",
        "              \n",
        "              # update sample tensor\n",
        "              x[:,d] = m\n",
        "\n",
        "              # Accumulate PSI based on which state (s) was sampled\n",
        "              selected_wavs = torch.where(x[:,d] > 0, psi_pos, psi_neg) \n",
        "              WAV = WAV*selected_wavs\n",
        "\n",
        "            else: \n",
        "\n",
        "              # if not sampling, m is a list of bits in column d \n",
        "              m = x[:,d]\n",
        "\n",
        "              # Accumulate PPSI based on which state (s) was sampled\n",
        "              selected_wavs = torch.where(m > 0, psi_pos, psi_neg) \n",
        "              WAV = WAV*selected_wavs\n",
        "\n",
        "            if requires_grad == True:\n",
        "\n",
        "              # eval_grads stores backpropagation values for out1 and out2.\n",
        "              # eval_grads[0] are the out1 grads for all samples (per param), \n",
        "              # eval_grads[1] are the out2 grads for all samples (per param). \n",
        "              eval_grads = [ [[]]*len(params) for outputs in range(len(self.evals)) ]\n",
        "\n",
        "              # Store the per-output grads in eval_grads\n",
        "              for output in range(len(self.evals)):\n",
        "\n",
        "                # backpropagate the current output (out1 or out2)\n",
        "                out[:,output].mean(0).backward(retain_graph=True)\n",
        "\n",
        "                # compute gradients for all samples \n",
        "                autograd_hacks.compute_grad1(self.model)\n",
        "                autograd_hacks.clear_backprops(self.model)\n",
        "\n",
        "                # store the calculated gradients for all samples \n",
        "                for param in range(len(params)):\n",
        "                  eval_grads[output][param] = params[param].grad1\n",
        "\n",
        "              # allocate space for gradient accumulation \n",
        "              if d == 0:\n",
        "                for param in range(len(params)):\n",
        "                  grads_per_param.append(torch.zeros_like(eval_grads[0][param]))\n",
        "              \n",
        "              # accumulate gradients per parameter based on sampled bits\n",
        "              for param in range(len(params)):\n",
        "\n",
        "                # reshape m and wavs so they can be accumulated/divided properly \n",
        "                reshaped_m = m.reshape(m.shape + (1,)*(grads_per_param[param].ndim-1))\n",
        "                reshaped_wavs = selected_wavs.reshape(selected_wavs.shape + (1,)*(grads_per_param[param].ndim-1))\n",
        "\n",
        "                # select the proper gradient to accumulate based on m \n",
        "                grads_per_param[param][:] += torch.where(reshaped_m[:] > 0, \n",
        "                                                         eval_grads[0][param][:]/reshaped_wavs[:], \n",
        "                                                         eval_grads[1][param][:]/reshaped_wavs[:])\n",
        "\n",
        "        return WAV.detach(), x.detach(), grads_per_param"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j805BCYgyQ_k"
      },
      "source": [
        "\"\"\"OPTIMIZATION\"\"\"\n",
        "\n",
        "def train(g, num_qubits, learning_rate):\n",
        "\n",
        "  # define device \n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  energies_per_g = []\n",
        "\n",
        "  # number of qubits\n",
        "  L = num_qubits\n",
        "  H = 2*L\n",
        "\n",
        "  J = 1 #sigma_z activation\n",
        "  B = g #sigma_x activation\n",
        "\n",
        "  # initialize network and model, put network on device \n",
        "  network = nn.Sequential(nn.Linear(L,H), \n",
        "                          nn.Tanh(),\n",
        "                          nn.Linear(H, 2),  \n",
        "                          nn.Tanh())\n",
        "  network.to(device) \n",
        "  model = QNADE(network)\n",
        "  params = list(model.parameters())\n",
        "\n",
        "  # Training hyperparameters \n",
        "  iters = 100\n",
        "  batch_size = 10000\n",
        "  lr = learning_rate\n",
        "\n",
        "  # initialize optimizer \n",
        "  optimizer = torch.optim.Adam(params=network.parameters(), lr=lr)\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # training loop \n",
        "  energies = []\n",
        "  for iter in range(iters):\n",
        "\n",
        "    #if iter%10 == 0: print(\"iter: {}\".format(iter))\n",
        "\n",
        "    # generate data \n",
        "    psi_omega, samples, grads_per_param = model(N_samples=batch_size)\n",
        "\n",
        "    # calculate local energies \n",
        "    epsilons = calculate_epsilons(model, samples, psi_omega, B, J).to(device)\n",
        "\n",
        "    # E is an average of local energies\n",
        "    E = epsilons.mean()\n",
        "    energies.append(E)\n",
        "    epsilons -= E \n",
        "    \n",
        "    # calculate O_k for a given parameter and number of samples \n",
        "    for param in range(len(params)):\n",
        "\n",
        "      # define O_k for a set of parameters \n",
        "      O_k = grads_per_param[param].detach()\n",
        "\n",
        "      # weight O_k according to epsilons \n",
        "      O_k *= epsilons.reshape(epsilons.shape + (1,)*(O_k.ndim-1))\n",
        "\n",
        "      # e_grad is an average of all O_k_s \n",
        "      e_grad = torch.mean(O_k, 0, keepdim=True).squeeze()\n",
        "\n",
        "      # update network parameter matrix with energy gradient  \n",
        "      with torch.no_grad():\n",
        "        params[param].grad.copy_(e_grad)\n",
        "\n",
        "    #optimize network based on e_grad \n",
        "    optimizer.step() \n",
        "\n",
        "  final_energy = min(energies)\n",
        "\n",
        "  energies_per_g.append(float(final_energy))\n",
        "\n",
        "  return min(energies_per_g)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yca_ZIS2yjb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0df717f-ba8a-4a89-e921-86de4f185f2a"
      },
      "source": [
        "\"\"\"GENERATE DATA FOR NUM_TRIALS\"\"\"\n",
        "\n",
        "B_val = 1\n",
        "lr = 0.01\n",
        "L = 2\n",
        "num_trials = 5\n",
        "\n",
        "E = calculate_expected_e(L, B_val)\n",
        "print(E)\n",
        "\n",
        "E_train = []\n",
        "for trial in range(num_trials):\n",
        "  print(trial)\n",
        "  E_train.append(train(B_val, L, lr))\n",
        "\n",
        "print(E_train) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-2.82842712474619\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "[-2.824357032775879, -2.5565147399902344, -2.4771957397460938, -2.828566074371338, -2.828655481338501]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3mt1bWlLOu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "1307608e-9c68-45dc-90e3-93a2b6cadcd1"
      },
      "source": [
        "\"\"\"BIN AND PLOT DATA\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "delta_E = [abs(E - calc_E) for calc_E in E_train]\n",
        "\n",
        "cut_bins = np.linspace(0,5,51) #needs to be adjusted depending on dataset generated  \n",
        "df = pd.DataFrame(delta_E, columns=['delta E'])\n",
        "df['bin'] = pd.cut(df['delta E'], bins=cut_bins).astype(str)\n",
        "df2 = df.groupby('bin').bin.count()\n",
        "\n",
        "ax = df2.plot(kind='bar')\n",
        "ax.set_xlabel(\"Delta E\")\n",
        "ax.set_ylabel(\"Count\")\n",
        "ax.set_title(\"{} Qubits\".format(L))\n",
        "fig = ax.get_figure()\n",
        "fig.tight_layout()\n",
        "fig.savefig(\"plot\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y64TZdvwa2Bl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}