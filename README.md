# Machine Learning Quantum Many-body Systems using Neural Autoregressive Distribution Estimation and GPU Acceleration

## Introduction 

Accurately modeling and solving interacting many-body systems is a very useful and challenging endeavor in quantum mechanics. Specifically, obtaining the ground state energy of a quantum many-body system has various applications in condensed matter, chemistry, nuclear, and other areas of physics. However, a persistent problem in the field of quantum mechanics is dealing with the exponentially increasing dimensionality of these many-body systems. The number of possible spin states in a quantum system of N qubits increases as d^N (where d is the number of possible discrete quantum values per qudit) with its wavefunction given by a linear superposition of basis states. As N grows, writing the many-body wavefunction becomes exponentially inefficient. Similarly, the dimensionality of both the Hamiltonian matrix and the computational cost required to compute it's eigenenergies also increases as d^N, making these calculations very difficult for large N. Today, it is infeasible to classically compute these ground states for systems of more than about 30 particles on most computers, with the upper limit generally agreed to be 51 particles when using the most powerful HPCs. Thus, with large systems, we introduce the need for an approximation of their wavefunction, also known as an "ansatz". Ideally, this compact representation of the wavefunction should have a number of parameters that scales polynomially rather than exponentially. In many cases, it is possible to obtain such an approximation because the the probability distribution of states in physical many-body systems only occupies a small region of the full Hilbert space. 

Over the years, many ansatze have been derived (mean-field, Jastrow, matrix product state, etc.). While these ansatze approximate the many-body wavefunction with a reduced number of parameters, they have limitations in their ability to simultaneously model high entanglement and variational freedom. However, neural networks have recently shown great promise in representing entangled many-body wavefunctions and have opened doors to new areas of research. In the neural network approach, a network is established with an input layer of N nodes, a hidden layer, and an output layer representing psi(s). If the hidden layer is constructed with a reasonable number of nodes (on the order of N), then the number of parameters (corresponding to the network weights and biases) scales polynomially. Furthermore, this approach introduces nonlinear mapping between inputs and outputs, thus allowing entanglement correlations to be encoded into the network. 

Finally, modern machine learning tools such as backpropagation, gradient descent algorithms, and GPU parallelization introduce the potential for a fully integrated system that efficiently optimizes a network to the ground state energy of an arbitrarily large many-body system. In this report we investigate the use of a feed forward neural network (FFNN) as an ansatz and introduce a proof of concept optimization system. 
